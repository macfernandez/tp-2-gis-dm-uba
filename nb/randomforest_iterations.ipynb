{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2401d954-3687-439b-a668-c219a35a5d18",
   "metadata": {},
   "source": [
    "# Entrenamiento iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "754fe51f-9bbc-4739-8e74-800473891684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "import joblib\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pyproj import CRS\n",
    "from copy import deepcopy\n",
    "from sqlite3 import connect\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc50e70-5593-4c74-88ea-d72ddb3d3411",
   "metadata": {},
   "source": [
    "## Conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65e2de2-f7c6-48cc-a57a-e3d53142d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiar según corresponda\n",
    "# train_sqlite_files debe contener los .sqlite generados a partir de la verdad de campo\n",
    "train_sqlite_files = glob('../data/verdad_campo_sqlite/*.sqlite')\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "\n",
    "for sf in train_sqlite_files:\n",
    "    file_name = os.path.basename(sf)\n",
    "    tile = re.search(r'\\d+',file_name).group()\n",
    "    cnx = connect(sf)\n",
    "    df = pd.read_sql_query(\"SELECT * FROM output\", cnx)\n",
    "    df['tile_file'] = tile\n",
    "    train_data = pd.concat([train_data, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a832c5d5-7d01-49d2-bf7f-dadc2d34128b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 35)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13016a21-cf58-4035-9ce7-fdb7ca399547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogc_fid</th>\n",
       "      <th>GEOMETRY</th>\n",
       "      <th>in1</th>\n",
       "      <th>id</th>\n",
       "      <th>cultivo</th>\n",
       "      <th>originfid</th>\n",
       "      <th>band_0</th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>band_3</th>\n",
       "      <th>...</th>\n",
       "      <th>band_19</th>\n",
       "      <th>band_20</th>\n",
       "      <th>band_21</th>\n",
       "      <th>band_22</th>\n",
       "      <th>band_23</th>\n",
       "      <th>band_24</th>\n",
       "      <th>band_25</th>\n",
       "      <th>band_26</th>\n",
       "      <th>band_27</th>\n",
       "      <th>tile_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00(I\\x80\\xe0\\xf6fO\\xc0\\xbe...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>7</td>\n",
       "      <td>0.42816</td>\n",
       "      <td>0.692352</td>\n",
       "      <td>0.36905</td>\n",
       "      <td>0.730617</td>\n",
       "      <td>...</td>\n",
       "      <td>4.816959</td>\n",
       "      <td>0.82200</td>\n",
       "      <td>0.410423</td>\n",
       "      <td>0.831812</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>2.95450</td>\n",
       "      <td>0.109526</td>\n",
       "      <td>0.861515</td>\n",
       "      <td>12544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00\\x1f|\\x14\"lkO\\xc0^\\x14\\x...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>8</td>\n",
       "      <td>0.41152</td>\n",
       "      <td>0.671952</td>\n",
       "      <td>0.42940</td>\n",
       "      <td>0.711504</td>\n",
       "      <td>...</td>\n",
       "      <td>4.774915</td>\n",
       "      <td>1.36300</td>\n",
       "      <td>0.441640</td>\n",
       "      <td>0.817090</td>\n",
       "      <td>0.587002</td>\n",
       "      <td>0.862946</td>\n",
       "      <td>3.15975</td>\n",
       "      <td>0.148569</td>\n",
       "      <td>0.859830</td>\n",
       "      <td>12544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00L).\\x93\\x08eO\\xc0fz\\xd9|...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>11</td>\n",
       "      <td>0.49848</td>\n",
       "      <td>0.794412</td>\n",
       "      <td>0.42270</td>\n",
       "      <td>0.805747</td>\n",
       "      <td>...</td>\n",
       "      <td>5.247081</td>\n",
       "      <td>1.27025</td>\n",
       "      <td>0.423015</td>\n",
       "      <td>0.849940</td>\n",
       "      <td>0.563715</td>\n",
       "      <td>0.884401</td>\n",
       "      <td>3.21300</td>\n",
       "      <td>0.130448</td>\n",
       "      <td>0.879770</td>\n",
       "      <td>12544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00\\x03X\\x12\\xb7\\xb0iO\\xc0[...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>12</td>\n",
       "      <td>0.52872</td>\n",
       "      <td>0.834804</td>\n",
       "      <td>0.79800</td>\n",
       "      <td>0.835724</td>\n",
       "      <td>...</td>\n",
       "      <td>5.583365</td>\n",
       "      <td>2.86100</td>\n",
       "      <td>0.432937</td>\n",
       "      <td>0.861866</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.892530</td>\n",
       "      <td>2.75850</td>\n",
       "      <td>0.430294</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>12544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00\\xa5\\x87\\x83F\\xd6\\\\O\\xc0...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>28</td>\n",
       "      <td>0.50560</td>\n",
       "      <td>0.799404</td>\n",
       "      <td>0.32025</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>...</td>\n",
       "      <td>5.668369</td>\n",
       "      <td>0.07450</td>\n",
       "      <td>0.453263</td>\n",
       "      <td>0.858904</td>\n",
       "      <td>0.589450</td>\n",
       "      <td>0.899895</td>\n",
       "      <td>2.88900</td>\n",
       "      <td>0.079681</td>\n",
       "      <td>0.894360</td>\n",
       "      <td>12544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ogc_fid                                           GEOMETRY     in1  id  \\\n",
       "0        1  b'\\x01\\x01\\x00\\x00\\x00(I\\x80\\xe0\\xf6fO\\xc0\\xbe...  014084   1   \n",
       "1        2  b'\\x01\\x01\\x00\\x00\\x00\\x1f|\\x14\"lkO\\xc0^\\x14\\x...  014084   1   \n",
       "2        3  b'\\x01\\x01\\x00\\x00\\x00L).\\x93\\x08eO\\xc0fz\\xd9|...  014084   1   \n",
       "3        4  b'\\x01\\x01\\x00\\x00\\x00\\x03X\\x12\\xb7\\xb0iO\\xc0[...  014084   1   \n",
       "4        5  b'\\x01\\x01\\x00\\x00\\x00\\xa5\\x87\\x83F\\xd6\\\\O\\xc0...  014084   1   \n",
       "\n",
       "  cultivo  originfid   band_0    band_1   band_2    band_3  ...   band_19  \\\n",
       "0    SOJA          7  0.42816  0.692352  0.36905  0.730617  ...  4.816959   \n",
       "1    SOJA          8  0.41152  0.671952  0.42940  0.711504  ...  4.774915   \n",
       "2    SOJA         11  0.49848  0.794412  0.42270  0.805747  ...  5.247081   \n",
       "3    SOJA         12  0.52872  0.834804  0.79800  0.835724  ...  5.583365   \n",
       "4    SOJA         28  0.50560  0.799404  0.32025  0.812116  ...  5.668369   \n",
       "\n",
       "   band_20   band_21   band_22   band_23   band_24  band_25   band_26  \\\n",
       "0  0.82200  0.410423  0.831812  0.543103  0.868833  2.95450  0.109526   \n",
       "1  1.36300  0.441640  0.817090  0.587002  0.862946  3.15975  0.148569   \n",
       "2  1.27025  0.423015  0.849940  0.563715  0.884401  3.21300  0.130448   \n",
       "3  2.86100  0.432937  0.861866  0.588915  0.892530  2.75850  0.430294   \n",
       "4  0.07450  0.453263  0.858904  0.589450  0.899895  2.88900  0.079681   \n",
       "\n",
       "    band_27  tile_file  \n",
       "0  0.861515      12544  \n",
       "1  0.859830      12544  \n",
       "2  0.879770      12544  \n",
       "3  0.891874      12544  \n",
       "4  0.894360      12544  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95c0c8-b127-40a2-bc35-199bb3f7183c",
   "metadata": {},
   "source": [
    "## Conjunto de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2aaaa6-4fd6-490b-bc56-20259113fb98",
   "metadata": {},
   "source": [
    "# cambiar según corresponda\n",
    "# pred_sqlite_files debe contener los .sqlite generados a partir de la máscara mask_agri_aoi\n",
    "pred_sqlite_files = glob('../data/selection_mask_agri_depto/*.sqlite')\n",
    "\n",
    "pred_data = pd.DataFrame()\n",
    "\n",
    "for sf in pred_sqlite_files:\n",
    "    file_name = os.path.basename(sf)\n",
    "    tile = re.search(r'\\d+',file_name).group()\n",
    "    cnx = connect(sf)\n",
    "    df = pd.read_sql_query(\"SELECT * FROM output\", cnx)\n",
    "    df['tile_file'] = tile\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "    pred_data = pd.concat([pred_data, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e977d8-1654-4d28-833c-e7d8496b9af2",
   "metadata": {},
   "source": [
    "pred_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35494afc-a081-49f0-9918-87fb36f21063",
   "metadata": {},
   "source": [
    "pred_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee6478d-8c03-457b-b12f-f98c3c5712a0",
   "metadata": {},
   "source": [
    "## Agregado de departamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea65f51-42ec-45f7-861c-5f7e72176487",
   "metadata": {},
   "source": [
    "# train_data está dentro de pred_data\n",
    "# saco esas filas de pred_data\n",
    "# así no predecimos con lo mismo con lo que entrenamos\n",
    "\n",
    "merged_data = pred_data.merge(train_data[['ogc_fid','tile_file','cultivo','id']], how='left', on=['ogc_fid','tile_file'], indicator=True)\n",
    "train_data = merged_data[merged_data._merge=='both'].drop(columns=['_merge']).assign(id=lambda x:x.id.astype('int'))\n",
    "pred_data = merged_data[merged_data._merge=='left_only'].drop(columns=['_merge'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a018e0a-406f-484a-9cfd-7c98554f575c",
   "metadata": {},
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2eda61-6eef-4c0f-91da-464315490913",
   "metadata": {},
   "source": [
    "pred_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d309a3-f979-49bf-82a7-2e8b05d195fe",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea57b00-be8e-4751-b4b1-79890ca2c05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'SOJA',\n",
       " 2: 'MAIZ',\n",
       " 3: 'MAIZ',\n",
       " 5: 'GIRASOL',\n",
       " 20: 'CAMPONATUR',\n",
       " 10: 'ALFALFA',\n",
       " 4: 'SOJA'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_id2cultivo = dict((\n",
    "    train_data[['id','cultivo']]\n",
    "    .drop_duplicates()\n",
    "    .assign(id=lambda x: x.id.astype('int'))\n",
    "    .itertuples(index=False, name=None))\n",
    ")\n",
    "map_id2cultivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58db2c36-a013-4133-8282-3a6392787db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_data.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee94fb21-48a6-4f1d-8157-ea254135a894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 10, 6: 20}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_le2id = dict(zip(le.transform(le.classes_), list(map(int,le.classes_))))\n",
    "\n",
    "map_le2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08505a9b-5ec0-4763-a2a2-0e6198b8457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogc_fid</th>\n",
       "      <th>GEOMETRY</th>\n",
       "      <th>in1</th>\n",
       "      <th>id</th>\n",
       "      <th>cultivo</th>\n",
       "      <th>originfid</th>\n",
       "      <th>band_0</th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>band_3</th>\n",
       "      <th>...</th>\n",
       "      <th>band_20</th>\n",
       "      <th>band_21</th>\n",
       "      <th>band_22</th>\n",
       "      <th>band_23</th>\n",
       "      <th>band_24</th>\n",
       "      <th>band_25</th>\n",
       "      <th>band_26</th>\n",
       "      <th>band_27</th>\n",
       "      <th>tile_file</th>\n",
       "      <th>id_le</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00(I\\x80\\xe0\\xf6fO\\xc0\\xbe...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>7</td>\n",
       "      <td>0.42816</td>\n",
       "      <td>0.692352</td>\n",
       "      <td>0.36905</td>\n",
       "      <td>0.730617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.82200</td>\n",
       "      <td>0.410423</td>\n",
       "      <td>0.831812</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>2.95450</td>\n",
       "      <td>0.109526</td>\n",
       "      <td>0.861515</td>\n",
       "      <td>12544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00\\x1f|\\x14\"lkO\\xc0^\\x14\\x...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>8</td>\n",
       "      <td>0.41152</td>\n",
       "      <td>0.671952</td>\n",
       "      <td>0.42940</td>\n",
       "      <td>0.711504</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36300</td>\n",
       "      <td>0.441640</td>\n",
       "      <td>0.817090</td>\n",
       "      <td>0.587002</td>\n",
       "      <td>0.862946</td>\n",
       "      <td>3.15975</td>\n",
       "      <td>0.148569</td>\n",
       "      <td>0.859830</td>\n",
       "      <td>12544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00L).\\x93\\x08eO\\xc0fz\\xd9|...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>11</td>\n",
       "      <td>0.49848</td>\n",
       "      <td>0.794412</td>\n",
       "      <td>0.42270</td>\n",
       "      <td>0.805747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.27025</td>\n",
       "      <td>0.423015</td>\n",
       "      <td>0.849940</td>\n",
       "      <td>0.563715</td>\n",
       "      <td>0.884401</td>\n",
       "      <td>3.21300</td>\n",
       "      <td>0.130448</td>\n",
       "      <td>0.879770</td>\n",
       "      <td>12544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00\\x03X\\x12\\xb7\\xb0iO\\xc0[...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>12</td>\n",
       "      <td>0.52872</td>\n",
       "      <td>0.834804</td>\n",
       "      <td>0.79800</td>\n",
       "      <td>0.835724</td>\n",
       "      <td>...</td>\n",
       "      <td>2.86100</td>\n",
       "      <td>0.432937</td>\n",
       "      <td>0.861866</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.892530</td>\n",
       "      <td>2.75850</td>\n",
       "      <td>0.430294</td>\n",
       "      <td>0.891874</td>\n",
       "      <td>12544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b'\\x01\\x01\\x00\\x00\\x00\\xa5\\x87\\x83F\\xd6\\\\O\\xc0...</td>\n",
       "      <td>014084</td>\n",
       "      <td>1</td>\n",
       "      <td>SOJA</td>\n",
       "      <td>28</td>\n",
       "      <td>0.50560</td>\n",
       "      <td>0.799404</td>\n",
       "      <td>0.32025</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07450</td>\n",
       "      <td>0.453263</td>\n",
       "      <td>0.858904</td>\n",
       "      <td>0.589450</td>\n",
       "      <td>0.899895</td>\n",
       "      <td>2.88900</td>\n",
       "      <td>0.079681</td>\n",
       "      <td>0.894360</td>\n",
       "      <td>12544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ogc_fid                                           GEOMETRY     in1  id  \\\n",
       "0        1  b'\\x01\\x01\\x00\\x00\\x00(I\\x80\\xe0\\xf6fO\\xc0\\xbe...  014084   1   \n",
       "1        2  b'\\x01\\x01\\x00\\x00\\x00\\x1f|\\x14\"lkO\\xc0^\\x14\\x...  014084   1   \n",
       "2        3  b'\\x01\\x01\\x00\\x00\\x00L).\\x93\\x08eO\\xc0fz\\xd9|...  014084   1   \n",
       "3        4  b'\\x01\\x01\\x00\\x00\\x00\\x03X\\x12\\xb7\\xb0iO\\xc0[...  014084   1   \n",
       "4        5  b'\\x01\\x01\\x00\\x00\\x00\\xa5\\x87\\x83F\\xd6\\\\O\\xc0...  014084   1   \n",
       "\n",
       "  cultivo  originfid   band_0    band_1   band_2    band_3  ...  band_20  \\\n",
       "0    SOJA          7  0.42816  0.692352  0.36905  0.730617  ...  0.82200   \n",
       "1    SOJA          8  0.41152  0.671952  0.42940  0.711504  ...  1.36300   \n",
       "2    SOJA         11  0.49848  0.794412  0.42270  0.805747  ...  1.27025   \n",
       "3    SOJA         12  0.52872  0.834804  0.79800  0.835724  ...  2.86100   \n",
       "4    SOJA         28  0.50560  0.799404  0.32025  0.812116  ...  0.07450   \n",
       "\n",
       "    band_21   band_22   band_23   band_24  band_25   band_26   band_27  \\\n",
       "0  0.410423  0.831812  0.543103  0.868833  2.95450  0.109526  0.861515   \n",
       "1  0.441640  0.817090  0.587002  0.862946  3.15975  0.148569  0.859830   \n",
       "2  0.423015  0.849940  0.563715  0.884401  3.21300  0.130448  0.879770   \n",
       "3  0.432937  0.861866  0.588915  0.892530  2.75850  0.430294  0.891874   \n",
       "4  0.453263  0.858904  0.589450  0.899895  2.88900  0.079681  0.894360   \n",
       "\n",
       "   tile_file  id_le  \n",
       "0      12544      0  \n",
       "1      12544      0  \n",
       "2      12544      0  \n",
       "3      12544      0  \n",
       "4      12544      0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['id_le'] = le.transform(train_data.id)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5240870-6685-4670-a2aa-f304a7e154e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/randomforest_parameters.json','r') as f:\n",
    "    parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2522359a-aceb-49a9-95cb-3499ae990d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_from_tile(in_raster):\n",
    "    with rasterio.open(in_raster) as src:\n",
    "        return(src.width, src.height, src.transform)\n",
    "\n",
    "def sliding_windows(size, step_size, width, height, whole=False):\n",
    "    \"\"\"Slide a window of +size+ by moving it +step_size+ pixels\"\"\"\n",
    "    w, h = size, size\n",
    "    sw, sh = step_size, step_size\n",
    "    end_i = height - h if whole else height\n",
    "    end_j = width - w if whole else width\n",
    "    for pos_i, i in enumerate(range(0, end_i, sh)):\n",
    "        for pos_j, j in enumerate(range(0, end_j, sw)):\n",
    "            real_w = w if whole else min(w, abs(width - j))\n",
    "            real_h = h if whole else min(h, abs(height - i))\n",
    "            yield Window(j, i, real_w, real_h), (pos_i, pos_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8cf33-7ad8-4ac2-8cbb-4657f8691644",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_train = pd.DataFrame()\n",
    "i = 0\n",
    "while True:\n",
    "    \n",
    "    # si el entrenamiento de la próxima iteración es mayor (en cantidad)\n",
    "    # a la data de entrenamiento, entonces toma el entrenamiento de la próxima\n",
    "    # iteración\n",
    "    # si no, toma la data de entrenamiento original (verdad de capo original)\n",
    "    # el entrenamiento de la próxima iteración es un df que se va enriqueciendo\n",
    "    # con la nueva verdad de campo predicha\n",
    "    # hago esto así porque, usando los tif, no sé cómo verificar si los pixeles\n",
    "    # están o no en la verdad de campo (entonces no quiero agregar la nueva\n",
    "    # verdad de camp al df que ya contiene la verdad de campo original\n",
    "    # porquee estaría duplicando los datos)\n",
    "    # así, primera iteración va a usar la data original y ya en la segunda\n",
    "    # iteración va a tomar el entrenamiento con la nueva verdad\n",
    "    if next_train.shape[0] >= train_data.shape[0]:\n",
    "        train_data = next_train\n",
    "\n",
    "    # arma carpeta para el output (i aumenta con las iteraciones)\n",
    "    n_iter = '{0:03d}'.format(i)\n",
    "    output_folder = os.path.join('..','model',f'randomforest_iterations_{n_iter}')\n",
    "    if os.path.exists(output_folder):\n",
    "        shutil.rmtree(output_folder)\n",
    "    os.mkdir(output_folder)\n",
    "    \n",
    "    # segmenta en train y test\n",
    "    X = train_data.filter(regex='band_').fillna(-99).to_numpy()\n",
    "    y = train_data['id_le'].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=.3, random_state=20220714, shuffle=True, stratify=y\n",
    "    )\n",
    "    \n",
    "    # instancia y entrena el modelo con set de entrenamiento\n",
    "    model = RandomForestClassifier(**parameters)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predice sobre el conjunto de testeo\n",
    "    probas = model.predict_proba(X_test)\n",
    "    output_proba_file = os.path.join(output_folder, f'probas_{n_iter}.npy')\n",
    "    np.save(output_proba_file, probas)\n",
    "    \n",
    "    y_hat = probas.argmax(axis=1)\n",
    "    \n",
    "    # guarda métricas\n",
    "    cmatrix = confusion_matrix(y_test, y_hat, normalize='all')\n",
    "    output_cmpatrix_file = os.path.join(output_folder, f'cmatrix_{n_iter}.npy')\n",
    "    np.save(output_cmpatrix_file, cmatrix)\n",
    "    \n",
    "    report = classification_report(y_test, y_hat, output_dict=True)\n",
    "    output_report_file = os.path.join(output_folder, f'report_{n_iter}.json')\n",
    "    with open(output_report_file, 'w') as f:\n",
    "        json.dump(report, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    kappa = cohen_kappa_score(y_test, y_hat)\n",
    "    output_kapp_file = os.path.join(output_folder, f'kapp_{n_iter}.txt')\n",
    "    with open(output_kapp_file, 'w') as f:\n",
    "        _ = f.write(str(kappa))\n",
    "    \n",
    "    # evalúa cantidad de aciertos y errores por nivel de confianza (cada 0.05)\n",
    "    predictions = pd.DataFrame({\n",
    "        'success':y_test==y_hat,\n",
    "        'score':probas.max(axis=1),\n",
    "    })\n",
    "    hits, confidence = np.histogram(predictions[predictions.success==True].score, 20, (0,1))\n",
    "    misses, _ = np.histogram(predictions[predictions.success==False].score, 20, (0,1))\n",
    "    hits_misses_df = (\n",
    "        pd\n",
    "        .DataFrame({'hit':hits, 'miss':misses, 'confidence':np.round(confidence[:-1], 2)})\n",
    "    )\n",
    "    output_success_file = os.path.join(output_folder, f'hits_misses_{n_iter}.csv')\n",
    "    hits_misses_df.to_csv(output_success_file, index=False)\n",
    "    \n",
    "    # selecciona el umbral\n",
    "    # umbral = score cuya cantidad de aciertos duplique la cantidad de errores + 1\n",
    "    threshold = hits_misses_df.loc[hits_misses_df.hit>(hits_misses_df.miss+1)*2,'confidence'].min()\n",
    "    output_threshold_file = os.path.join(output_folder, f'threshold_{n_iter}.txt')\n",
    "    with open(output_threshold_file, 'w') as f:\n",
    "        _ = f.write(str(threshold))\n",
    "\n",
    "    # instancia y entrena el modelo con set de entrenamiento + validación\n",
    "    iter_X = train_data.filter(regex='band_').fillna(-99999).to_numpy()\n",
    "    iter_y = train_data['id_le'].to_numpy()\n",
    "\n",
    "    model = RandomForestClassifier(**parameters)\n",
    "    model.fit(iter_X, iter_y)\n",
    "    output_model_file = os.path.join(output_folder, f'model_{n_iter}.joblib')\n",
    "    _ = joblib.dump(model, output_model_file)\n",
    "    \n",
    "    # levanta los .tif para predecir\n",
    "    pred_tif = glob('../data/feature_importance/12*.tif')\n",
    "    \n",
    "    vc_len = X_train.shape[0] + X_test.shape[0]\n",
    "    new_vc_len = 0\n",
    "    for tif in pred_tif:\n",
    "        # detecta nombre del raster\n",
    "        # 12544.tif o 00000.tif\n",
    "        name_raster = os.path.basename(tif)\n",
    "        \n",
    "        print(f'+++ PREDICCIÓN PARA TILE: {name_raster}')\n",
    "        \n",
    "        # levanta la metadata del tif\n",
    "        width, height, transform = metadata_from_tile(tif)\n",
    "        # arma las ventanas de 100x100\n",
    "        windows = sliding_windows(100, 100, width, height)\n",
    "    \n",
    "        # si no está en la primera iteración\n",
    "        # busca el raster para enmascarar de la iteración anterior\n",
    "        if i>0:\n",
    "            prev_i = i-1\n",
    "            prev_iter = '{0:03d}'.format(prev_i)\n",
    "            prev_folder = output_folder.replace(n_iter, prev_iter)\n",
    "            prev_tif = os.path.join(prev_folder, name_raster)\n",
    "        \n",
    "        out_raster = os.path.join(output_folder, name_raster)\n",
    "        with rasterio.open(\n",
    "            out_raster, 'w', driver='GTiff', count=1,\n",
    "            width=width, height=height, dtype=np.float64, transform=transform,\n",
    "            crs=CRS.from_epsg(4326), compress='lzw') as dst:\n",
    "            \n",
    "            windows = list(windows)\n",
    "            windows_len = len(windows)\n",
    "            wn = 0\n",
    "            for window in windows:\n",
    "                print(f'... Prediciendo ventana {wn} de {windows_len}')\n",
    "                print(window)\n",
    "                wn +=1\n",
    "                \n",
    "                win=window[0]\n",
    "                # abre ventana en el raster original\n",
    "                src = rasterio.open(tif)\n",
    "                img = src.read(window=win)\n",
    "                r,m,n = img.shape\n",
    "                \n",
    "                # arma un dataframe con la data para predecir\n",
    "                # shape: 10000 filas (100x100 pixeles) x 28 columnas (bandas)\n",
    "                img_df = (\n",
    "                    pd.DataFrame(img.reshape(r,m*n))\n",
    "                    .T.fillna(-99)\n",
    "                )\n",
    "                img_df.rename(columns={col:f'band_{col}' for col in img_df.columns}, inplace=True)\n",
    "                \n",
    "                # si no está en la primera iteración\n",
    "                # arma un dataframe con la data para enmascarar\n",
    "                # shape: 10000 filas (100x100 pixeles) x 28 columnas (bandas)\n",
    "                if i>0:\n",
    "                    # abre ventana en el raster de la iteración previa\n",
    "                    # para enmascarar\n",
    "                    src_mask = rasterio.open(prev_tif)\n",
    "                    mask = src_mask.read(window=win) \n",
    "                    mask_df = pd.DataFrame(mask.reshape(r,m*n)).T\n",
    "\n",
    "                #img_df.rename(columns={col:f'band_{col}' for col in img_df.columns}, inplace=True)\n",
    "                # agrega columna con predicciones\n",
    "                iter_prediction = model.predict_proba(img_df.to_numpy())\n",
    "                img_df['id_le'] = iter_prediction.argmax(axis=1)\n",
    "                img_df['score'] = iter_prediction.max(axis=1)\n",
    "\n",
    "                # si el score de la predicción supera al umbral\n",
    "                # agrega esa info al entrenamiento de la próxima iteración\n",
    "                new_vc = img_df[img_df.score>=threshold]\n",
    "                new_vc['id_le'] = new_vc.id_le.astype('int')\n",
    "                next_train = pd.concat([next_train, new_vc])\n",
    "                new_vc_len += new_vc.shape[0]\n",
    "                \n",
    "                # asigna id real\n",
    "                # enmascara las predicciones cuyo score no supera al umbral (-99)\n",
    "                # y lo guarda en un nuevo .tif\n",
    "                img_df['id'] = img_df.id_le.map(map_le2id)\n",
    "                img_df.loc[img_df.score<threshold, 'id'] = -99\n",
    "                print(img_df.id.unique())\n",
    "                tif_class = np.expand_dims(img_df.id.to_numpy().reshape(n,m), axis=0)\n",
    "                dst.write(tif_class, window=win)\n",
    "                \n",
    "                # cuando se hace la predicción hay que revisar si hay un .tif del modelo para enmascarar\n",
    "                # (solo se predicen los pixeles que tengan NA)          \n",
    "    \n",
    "    output_vc_file = os.path.join(output_folder, f'verdad_campo_{n_iter}.txt')\n",
    "    with open(output_vc_file, 'w') as f:\n",
    "        _ = f.write(f'''verdad_campo_entrenamiento,{vc_len}\\nvedad_campo_nueva{new_vc_len}\\n''')\n",
    "    \n",
    "    \n",
    "    # imprime información\n",
    "    print(f'''\\n*** ITERACIÓN #{i:03d}\n",
    "    - Pixeles de entrenamiento: {X_train.shape[0]}\n",
    "    - Pixeles de validación: {X_test.shape[0]}\n",
    "    - Probabilidades sobre train guardadas en {output_proba_file}\n",
    "    - Umbral definido: {threshold}\n",
    "    - Pixeles del modelo final: {vc_len}\n",
    "    - Modelo guardado en: {output_model_file}\n",
    "    - Nueva verdad de campo predicha: {new_vc_len}''')\n",
    "    \n",
    "    if new_vc_len == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0097f827-c8ed-4770-96c7-9a01b25bf763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/feature_importance/12544.tif'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a48a920-e68b-424f-8e1a-6fbb054db5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/randomforest_iterations_000/12544.tif'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "80d25d7e-20de-4b30-889d-4a7f886ca0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, transform = metadata_from_tile(tif)\n",
    "# arma las ventanas de 100x100\n",
    "windows = sliding_windows(100, 100, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "801631cd-921e-49d9-b997-0f03a1bbe5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3349/1708422004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# origin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrasterio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtif\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     img_df = (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chicho = 0\n",
    "for window in list(windows):\n",
    "    print(chicho)\n",
    "    # origin\n",
    "    src = rasterio.open(tif)\n",
    "    img = src.read(window=win)\n",
    "    r,m,n = img.shape\n",
    "    img_df = (\n",
    "                    pd.DataFrame(img.reshape(r,m*n))\n",
    "                    .T.fillna(-99)\n",
    "                )\n",
    "    img_df.rename(columns={col:f'band_{col}' for col in img_df.columns}, inplace=True)\n",
    "    # mask\n",
    "    src_mask = rasterio.open(out_raster)\n",
    "    mask = src_mask.read(window=win) \n",
    "    r_mask,m_mask,n_mask = mask.shape\n",
    "    mask_df = (\n",
    "        pd.DataFrame(mask.reshape(r_mask,m_mask*n_mask), index=['id']).T\n",
    "    )\n",
    "    b = mask_df.id.to_list()\n",
    "    if 3 in b:\n",
    "        print(mask_df)\n",
    "        print(mask_df[mask_df.id==3])\n",
    "    #print(mask_df.loc[mask_df.id==0])\n",
    "    chicho+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7587383e-0175-451f-b4b9-644fbf4e0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window, _ in tqdm(windows):\n",
    "                print(window)\n",
    "                win = window[0]\n",
    "                \n",
    "                # abre ventana en el raster original\n",
    "                src = rasterio.open(tif)\n",
    "                img = src.read(window=win) \n",
    "                                \n",
    "                r,m,n = img.shape\n",
    "                \n",
    "                # arma un dataframe con la data para predecir\n",
    "                # shape: 10000 filas (100x100 pixeles) x 28 columnas (bandas)\n",
    "                img_df = (\n",
    "                    pd.DataFrame(img.reshape(r,m*n))\n",
    "                    .T.fillna(-99)\n",
    "                )\n",
    "                img_df.rename(columns={col:f'band_{col}' for col in img_df.columns}, inplace=True)\n",
    "                \n",
    "                # si no está en la primera iteración\n",
    "                # arma un dataframe con la data para enmascarar\n",
    "                # shape: 10000 filas (100x100 pixeles) x 28 columnas (bandas)\n",
    "                if i>0:\n",
    "                    # abre ventana en el raster de la iteración previa\n",
    "                    # para enmascarar\n",
    "                    src_mask = rasterio.open(prev_tif)\n",
    "                    mask = src_mask.read(window=win) \n",
    "                    mask_df = pd.DataFrame(mask.reshape(r,m*n)).T\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734d4a0-59b0-43a5-9411-1d7a7d27df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "   \n",
    "\n",
    "    # separa entre nuevo train y nuevo pred\n",
    "    add_to_train = predictions.query(f'pred_score >= {threshold}').copy()\n",
    "    continue_pred = predictions.query(f'pred_score < {threshold}').copy()\n",
    "    train_data_len, add_to_train_len , continue_pred_len = iter_train_data.shape[0], add_to_train.shape[0] , continue_pred.shape[0]\n",
    "    output_pixels_file = os.path.join(output_folder, f'pixels_{n_iter}.csv')\n",
    "    (\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [f'De entrenamiento', train_data_len],\n",
    "                [f'Con proba>={threshold}', add_to_train_len],\n",
    "                [f'Con proba<{threshold}', continue_pred_len]\n",
    "            ],\n",
    "            columns=['Pyxels_type','Pixels']\n",
    "        )\n",
    "        .to_csv(output_pixels_file, index=False)\n",
    "    )\n",
    "\n",
    "    output_deptos_file = os.path.join(output_folder, f'pred_deptos_{n_iter}.csv')\n",
    "    (\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                [f'De entrenamiento', train_data_len],\n",
    "                [f'Con proba>={threshold}', add_to_train_len],\n",
    "                [f'Con proba<{threshold}', continue_pred_len]\n",
    "            ],\n",
    "            columns=['Pyxels_type','Pixels']\n",
    "        )\n",
    "        .to_csv(output_pixels_file, index=False)\n",
    "    )\n",
    "\n",
    "    # pasa predicción a las columna id (target)\n",
    "    # y lo agrega al train original\n",
    "    add_to_train['id_le'] = add_to_train['pred_class']\n",
    "    add_to_train['id'] = add_to_train.id_le.apply(lambda x: map_le2id.get(x))\n",
    "    add_to_train['cultivo'] = add_to_train.id.apply(lambda x: map_id2cultivo.get(x))\n",
    "\n",
    "    iter_deptos_prediction = os.path.join(output_folder,f'randomforest__deptos_prediction_{n_iter}.csv')\n",
    "    (\n",
    "        add_to_train\n",
    "        .groupby(['cultivo','nombre'], as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={'size':'pixels','nombre':'departamento'})\n",
    "        .assign(ha=lambda x: x.pixels*0.04)\n",
    "        .to_csv(iter_deptos_prediction, index=False)\n",
    "    )\n",
    "    iter_train_data =iter_train_data.append(add_to_train, ignore_index=True)\n",
    "    iter_pred_data = continue_pred\n",
    "\n",
    "    # imprime información\n",
    "    print('''\\n*** ITERACIÓN #{0:03d}\n",
    "    - Modelo guardado en {1}\n",
    "    - Probabilidades guardadas en {2}\n",
    "    - Pixeles de entrenamiento: {3}\n",
    "    - Pixeles con proba>={4}: {5}\n",
    "    - Pixeles con proba<{4}: {6}'''.format(i, output_model_file, output_proba_file, train_data_len, threshold, add_to_train_len , continue_pred_len))\n",
    "    i += 1\n",
    "    if (add_to_train_len == 0) or (continue_pred_len == 0):\n",
    "        break\n",
    "\n",
    "# reemplaza na en columna pred_class con 'vc_original'\n",
    "# (los pixeles que no tiene pred_class son los pieles de verdad de campo originales)\n",
    "# y guarda la predicción final\n",
    "nueva_vc_prediction = os.path.join(threshold_folder,f'randomforest_nueva_vc_prediction.csv')\n",
    "iter_train_data.to_csv(nueva_vc_prediction)\n",
    "nueva_vc_deptos = os.path.join(threshold_folder,f'randomforest_nueva_vc_deptos.csv')\n",
    "(\n",
    "    iter_train_data\n",
    "    .groupby(['cultivo','nombre'], as_index=False)\n",
    "    .size()\n",
    "    .rename(columns={'size':'pixels','nombre':'departamento'})\n",
    "    .assign(ha=lambda x: x.pixels*0.04)\n",
    "    .to_csv(nueva_vc_deptos, index=False)\n",
    ")\n",
    "\n",
    "\n",
    "# pasa predicción a las columna id (target)\n",
    "# y agrega las predicciones que no superaron el umbral a la nueva verdad de campo\n",
    "# (i.e. a las que sí lo superaron)\n",
    "# así, tenemos el conjunto completo y calculamos las ha sobre el total\n",
    "continue_pred['id_le'] = continue_pred['pred_class']\n",
    "continue_pred['id'] = continue_pred.id_le.apply(lambda x: map_le2id.get(x))\n",
    "continue_pred['cultivo'] = continue_pred.id.apply(lambda x: map_id2cultivo.get(x))\n",
    "\n",
    "total_final_prediction = os.path.join(threshold_folder,f'randomforest_total_final_prediction.csv')\n",
    "total_prediction = iter_train_data.append(continue_pred)\n",
    "total_prediction.to_csv(total_final_prediction)\n",
    "\n",
    "total_final_deptos = os.path.join(threshold_folder,f'randomforest_total_final_deptos.csv')\n",
    "(\n",
    "    total_prediction\n",
    "    .groupby(['cultivo','nombre'], as_index=False)\n",
    "    .size()\n",
    "    .rename(columns={'size':'pixels','nombre':'departamento'})\n",
    "    .assign(ha=lambda x: x.pixels*0.04)\n",
    "    .to_csv(total_final_deptos, index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7154b-9164-42f2-8607-814bea161efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
