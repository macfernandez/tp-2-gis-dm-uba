{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2401d954-3687-439b-a668-c219a35a5d18",
   "metadata": {},
   "source": [
    "# Entrenamiento iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754fe51f-9bbc-4739-8e74-800473891684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sqlite3 import connect\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc50e70-5593-4c74-88ea-d72ddb3d3411",
   "metadata": {},
   "source": [
    "## Conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e2de2-f7c6-48cc-a57a-e3d53142d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sqlite_files = glob('../data/selection_verdad_campo/*.sqlite')\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "\n",
    "for sf in train_sqlite_files:\n",
    "    file_name = os.path.basename(sf)\n",
    "    tile = re.search(r'\\d+',file_name).group()\n",
    "    cnx = connect(sf)\n",
    "    df = pd.read_sql_query(\"SELECT * FROM output\", cnx)\n",
    "    df['tile_file'] = tile\n",
    "    train_data = pd.concat([train_data, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a832c5d5-7d01-49d2-bf7f-dadc2d34128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13016a21-cf58-4035-9ce7-fdb7ca399547",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95c0c8-b127-40a2-bc35-199bb3f7183c",
   "metadata": {},
   "source": [
    "## Conjunto de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468b355-411e-4fad-bfbc-feaee30b74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sqlite_files = glob('../data/selection_mask_agri_aoi/*.sqlite')\n",
    "\n",
    "pred_data = pd.DataFrame()\n",
    "\n",
    "for sf in pred_sqlite_files:\n",
    "    file_name = os.path.basename(sf)\n",
    "    tile = re.search(r'\\d+',file_name).group()\n",
    "    cnx = connect(sf)\n",
    "    df = pd.read_sql_query(\"SELECT * FROM output\", cnx)\n",
    "    df['tile_file'] = tile\n",
    "    pred_data = pd.concat([pred_data, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f460d-2a3d-4fc7-9a11-a362062b80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7f6ab-39b9-4c74-9205-107131a96fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d309a3-f979-49bf-82a7-2e8b05d195fe",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5240870-6685-4670-a2aa-f304a7e154e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/randomforest_parameters.json','r') as f:\n",
    "    parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd792c8-087a-4732-a589-85dd1d20e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.4, 0.56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734d4a0-59b0-43a5-9411-1d7a7d27df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in thresholds:\n",
    "    \n",
    "    print(f'+++++ PREDICCIONES PARA THRESHOLD {threshold}')\n",
    "    \n",
    "    threshold_folder = os.path.join('..','model',f'threshhold_{threshold}')\n",
    "    os.makedirs(threshold_folder, exist_ok=True)\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        \n",
    "        # arma carpeta para el output (i aumenta con las iteraciones)\n",
    "        n_iter = '{0:03d}'.format(i)\n",
    "        output_folder = os.path.join(threshold_folder,f'randomforest_iterations_{n_iter}')\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        # toma los datasets\n",
    "        columns = train_data.filter(regex='band_').columns.to_list()\n",
    "        X_train = train_data.filter(regex='band_').fillna(-99999).to_numpy()\n",
    "        y_train = train_data.id.to_numpy()\n",
    "        X_pred = pred_data.filter(regex='band_').fillna(-99999).to_numpy()\n",
    "        \n",
    "        # instancia y entrena el modelo\n",
    "        model = RandomForestClassifier(**parameters)\n",
    "        model.fit(X_train, y_train)\n",
    "        output_model_file = os.path.join(output_folder, f'model_{n_iter}.joblib')\n",
    "        _ = joblib.dump(model, output_model_file)\n",
    "        \n",
    "        # predice\n",
    "        probas = model.predict_proba(X_pred)\n",
    "        output_proba_file = os.path.join(output_folder, f'probas_{n_iter}.npy')\n",
    "        np.save(output_proba_file, probas)\n",
    "        predictions = pred_data.assign(pred_class=probas.argmax(axis=1), pred_score=probas.max(axis=1))\n",
    "        \n",
    "        # separa entre nuevo train y nuevo pred\n",
    "        add_to_train = predictions.query(f'pred_score >= {threshold}').copy()\n",
    "        continue_pred = predictions.query(f'pred_score < {threshold}').copy()\n",
    "        train_data_len, add_to_train_len , continue_pred_len = train_data.shape[0], add_to_train.shape[0] , continue_pred.shape[0]\n",
    "        output_pixels_file = os.path.join(output_folder, f'pixels_{n_iter}.csv')\n",
    "        (\n",
    "            pd.DataFrame(\n",
    "                [\n",
    "                    [f'De entrenamiento', train_data_len],\n",
    "                    [f'Con proba>={threshold}', add_to_train_len],\n",
    "                    [f'Con proba<{threshold}', continue_pred_len]\n",
    "                ],\n",
    "                columns=['Pyxels_type','Pixels']\n",
    "            )\n",
    "            .to_csv(output_pixels_file, index=False)\n",
    "        )\n",
    "        \n",
    "        # pasa predicción a las columna id (target)\n",
    "        # y lo agrega al train original\n",
    "        add_to_train['id'] = add_to_train['pred_class']\n",
    "        train_data = train_data.append(add_to_train, ignore_index=True)\n",
    "        pred_data = continue_pred\n",
    "        \n",
    "        # imprime información\n",
    "        print('''\\n*** ITERACIÓN #{0:03d}\n",
    "        - Modelo guardado en {1}\n",
    "        - Probabilidades guardadas en {2}\n",
    "        - Pixeles de entrenamiento: {3}\n",
    "        - Pixeles con proba>={4}: {5}\n",
    "        - Pixeles con proba<{4}: {6}'''.format(i, output_model_file, output_proba_file, train_data_len, threshold, add_to_train_len , continue_pred_len))\n",
    "        i += 1\n",
    "        if add_to_train_len == 0:\n",
    "            break\n",
    "\n",
    "    # reemplaza na en columna pred_class con 'vc_original'\n",
    "    # (los pixeles que no tiene pred_class son los pieles de verdad de campo originales)\n",
    "    # y guarda la predicción final\n",
    "    final_prediction = os.path.join(threshold_folder,f'randomforest_iterations_final_prediction.csv')\n",
    "    train_data['pred_class'] = train_data.pred_class.fillna('vc_original')\n",
    "    train_data.to_csv(final_prediction)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
